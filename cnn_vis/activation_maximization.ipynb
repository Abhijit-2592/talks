{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation Maximization\n",
    "\n",
    "The idea behind activation maximization is simple in hindsight - Generate an input image that maximizes the filter output activations. i.e., we compute\n",
    "\n",
    "$$\\frac{\\partial ActivationMaximizationLoss}{\\partial input}$$\n",
    "\n",
    "**NOTE**:\n",
    "\n",
    "To visualize activation over final dense layer outputs, we need to switch the `softmax` activation out for `linear` since gradient of output node will depend on all the other node activations. Doing this in keras is tricky, so we provide `utils.apply_modifications` to modify network parameters and rebuild the graph.\n",
    "\n",
    "If this swapping is not done, the results might be suboptimal. We will start by swapping out 'softmax' for 'linear' and compare what happens if we dont do this at the end.\n",
    "\n",
    "**Caution**:\n",
    "\n",
    "This NOTEBOOK will take time to run, since this visualization is **optimization** based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras.applications import VGG16\n",
    "from vis.utils import utils\n",
    "from keras import activations\n",
    "\n",
    "# Build the VGG16 network with ImageNet weights\n",
    "model = VGG16(weights='imagenet', include_top=True)\n",
    "\n",
    "# Utility to search for layer index by name. \n",
    "# Alternatively we can specify this as -1 since it corresponds to the last layer.\n",
    "layer_idx = utils.find_layer_idx(model, 'predictions')\n",
    "\n",
    "# Swap softmax with linear\n",
    "model.layers[layer_idx].activation = activations.linear\n",
    "model = utils.apply_modifications(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing a specific output category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try visualizing a specific output category. We will pick `ouzel` which corresponds to imagenet category `20`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vis.visualization import visualize_activation\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (18, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(visualize_activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# 20 is the imagenet category for 'ouzel'\n",
    "img = visualize_activation(model, layer_idx, filter_indices=20)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm, that sort of looks like a bird. Lets see if we can get better results with more iterations. This time, lets see the verbose output during the optimization process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 20 is the imagenet category for 'ouzel'\n",
    "img = visualize_activation(model, layer_idx, filter_indices=20, max_iter=300, verbose=False)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the loss appears to be converging. So more iterations definitely seem to give better output. One way to get crisper results is to use `Jitter` input_modifier. As the name suggests, `Jitter` moves pixels around in the image. Lets try this out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vis.input_modifiers import Jitter\n",
    "\n",
    "# 20 is the imagenet category for 'ouzel'\n",
    "# Jitter 16 pixels along all dimensions during the optimization process.\n",
    "img = visualize_activation(model, layer_idx, filter_indices=20, max_iter=500, input_modifiers=[Jitter(16)])\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at that! Not only has the conv net captured what it means to be an ouzel, but it also seems to encode for different orientations and scales, a further proof of rotational and scale invariance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try this for a bunch of other random categories. This will take a while. Go grab a nice cup of coffee and prepare to be amused :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./imagenet_labelmap.json\", \"r\") as f:\n",
    "    labelmap = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "categories = np.random.permutation(1000)[:16]\n",
    "\n",
    "vis_images = []\n",
    "image_modifiers = [Jitter(16)]\n",
    "for idx in categories:    \n",
    "    img = visualize_activation(model, layer_idx, filter_indices=idx, max_iter=500, input_modifiers=image_modifiers)\n",
    "    \n",
    "    # Reverse lookup index to imagenet label and overlay it on the image.\n",
    "    img = utils.draw_text(img, labelmap(str(idx)))\n",
    "    vis_images.append(img)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (50, 50)\n",
    "stitched = utils.stitch_images(vis_images, cols=4)\n",
    "plt.axis('off')\n",
    "plt.imshow(stitched)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations without swapping softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As alluded at the beginning of the tutorial, we want to compare and see what happens if we didnt swap out softmax for linear activation.\n",
    "\n",
    "Lets try the `ouzel` visualization again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "layer_idx = utils.find_layer_idx(model, 'predictions')\n",
    "\n",
    "# Swap linear back with softmax\n",
    "model.layers[layer_idx].activation = activations.softmax\n",
    "model = utils.apply_modifications(model)\n",
    "\n",
    "img = visualize_activation(model, layer_idx, filter_indices=20, input_modifiers=[Jitter(16)])\n",
    "plt.rcParams['figure.figsize'] = (18, 6)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It does not work! The reason is that maximizing an output node can be done by minimizing other outputs. Softmax is weird that way. It is the only activation that depends on other node output(s) in the layer."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
